name: run-action

on: 
  push

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  build:
    runs-on: windows-latest
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0 # <-- clone with complete history
          
      - shell: cmd
        run: |
          .\setup.cmd
          
      - shell: cmd
        run: |
          .\install-packages.cmd

      - shell: cmd
        run: |
          cd /d "%USERPROFILE%\Downloads" &&^
          curl https://github.com/ggml-org/llama.cpp/releases/download/b6615/llama-b6615-bin-win-cpu-x64.zip -L -J --output llama.zip &&^
          7z x llama.zip &&^
          
      - shell: cmd
        run: |
          cd /d "%USERPROFILE%\Downloads" &&^
          curl https://huggingface.co/audreyt/Taiwan-LLM-7B-v2.1-chat-GGUF/resolve/main/Taiwan-LLM-7B-v2.1-chat-Q5_K_M.gguf -L -O -J &&^
          dir
          
      - shell: cmd
        run: |
          cd /d "%USERPROFILE%\Downloads" &&^
          .\llama-server.exe -m Taiwan-LLM-7B-v2.1-chat-Q5_K_M.gguf

      - shell: cmd
        run: |
          .\run.cmd
          
